<!DOCTYPE html>
<html lang="zh-Hans-CN"><head><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=Edge"/><link rel="stylesheet" type="text/css" href="css/modern-norm.min.css"/><link rel="stylesheet" type="text/css" href="css/prism.min.css"/><link rel="stylesheet" type="text/css" href="css/katex.min.css"/><link rel="stylesheet" type="text/css" href="css/wolai.css"/><title>ML&amp;DM-Seminar - wolai 笔记</title><link rel="shortcut icon"></link></head><body class="full-width"><header><div class="image"></div><div class="title"><div class="banner"><div class="icon"></div></div><div data-title="ML&amp;DM-Seminar" class="main-title"></div></div></header><article><hr id="hQsvVtPnb8RADomT6fvjf" class="wolai-block"/><div id="gsV7XokuPSMDnGoq9DC4HW" class="wolai-block wolai-text"><div><span class="inline-wrap">ML&amp;DM-Seminar (Seminar on Machine Learning and Data Mining) 是一个以机器学习与数据挖掘为主题的线上中文研讨班。在每一次研讨班中，会有<span class="jill"></span>1-2<span class="jill"></span>位学生或邀请嘉宾分享其近期的工作。欢迎大家积极参与交流！</span></div></div><div id="d1PVdYCPwSjENGeJhTN96b" class="wolai-block wolai-text"><div><span class="inline-wrap"></span><br/></div></div><h2 id="5G61PtUjWPmtdv4RX5Npef" class="wolai-block"><span class="inline-wrap">Schedule</span></h2><hr id="hGXWwXt35vvTS5GEayrWvP" class="wolai-block"/><div id="9iy3boWynKMqpNHARzhBxM" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>2024</b></span></div></div><div id="nZEfJFtX11AquYCVpkzcpH" class="wolai-block wolai-simple-table"><table><tbody><tr><td style="width: 79px"><span class="inline-wrap">Time</span></td><td style="width: 152px"><span class="inline-wrap">Speaker</span></td><td style="width: 630px"><span class="inline-wrap">Talk Title</span></td><td style="width: 111px"><span class="inline-wrap">Papers</span></td><td style="width: 90px"><span class="inline-wrap">Slides</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">1/23</span></td><td style="width: 152px"><span class="inline-wrap">Tian-Shuang Wu</span></td><td style="width: 630px"><span class="inline-wrap">Compressing Models with Few Samples: Mimicking then Replacing (CVPR 2022)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/wang2022compressing_cvpr.pdf"><span>1</span></a></span><span class="inline-wrap">] [</span><span class="inline-wrap"><a href="papers/wang2021distilling_tpami.pdf"><span>2</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/MIR.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">1/30</span></td><td style="width: 152px"><span class="inline-wrap">Tian-Shuang</span><span class="inline-wrap"> Wu</span></td><td style="width: 630px"><span class="inline-wrap">Practical Network Acceleration with Tiny Sets (CVPR 2023)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/wang2023practical_arxiv.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/PRACTISE.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">1/30</span></td><td style="width: 152px"><span class="inline-wrap">Ning Chen</span></td><td style="width: 630px"><span class="inline-wrap">Summary of Multi-Label Learning</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/tan2022novel_tkde.pdf"><span>1</span></a></span><span class="inline-wrap">] [</span><span class="inline-wrap"><a href="papers/hou2016multi_aaai.pdf"><span>2</span></a></span><span class="inline-wrap">] [</span><span class="inline-wrap"><a href="papers/zhang2015leveraging_icdm.pdf"><span>3</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Summary of Multi-Label Learning.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">2/6</span></td><td style="width: 152px"><span class="inline-wrap">Ning Chen</span></td><td style="width: 630px"><span class="inline-wrap">Scalable Label Distribution Learning for Multi-Label Classification (ArXiv 2023)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/zhao2023scalable_arxiv.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Scalable Label Distribution Learning for Multi-Label Classification.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">3/5</span></td><td style="width: 152px"><span class="inline-wrap">Ning Chen</span></td><td style="width: 630px"><span class="inline-wrap">A k-Nearest Neighbor Based Algorithm for Multi-label Classification (ICGC 2005)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/zhang2005nearest_grc.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/A k-Nearest Neighbor Based Algorithm for Multi-label Classification.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">3/5</span></td><td style="width: 152px"><span class="inline-wrap">Tian-Shuang Wu</span></td><td style="width: 630px"><span class="inline-wrap">Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks (WACV 2018)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/Grad-CAM++.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Grad-CAM++.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">4/2</span></td><td style="width: 152px"><span class="inline-wrap">Tian-Shuang Wu</span></td><td style="width: 630px"><span class="inline-wrap">Open-Sampling Exploring Out-of-Distribution Data for Re-balancing (ICML 2022)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/Open-Sampling Exploring Out-of-Distribution Data for Re-balancing.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Open-Sampling.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">4/13</span></td><td style="width: 152px"><span class="inline-wrap">Ning Chen</span></td><td style="width: 630px"><span class="inline-wrap">Progressive Enhancement of Label Distributions for Partial Multilabel Learning (TNNLS 2023)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/PELATED.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Progressive Enhancement of Label Distributions for Partial Multilabel Learning.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">5/4</span></td><td style="width: 152px"><span class="inline-wrap">Ning Chen</span></td><td style="width: 630px"><span class="inline-wrap">Multi-Label Supervised Contrastive Learning (AAAI 2024)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/Multi-Label Supervised Contrastive Learning.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Multi-Label Supervised Contrastive Learning.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr></tbody></table></div><div id="qzHpwwRKVQE8WobFrct1gX" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>2025</b></span></div></div><div id="f8ZctDEt8nHkV2syNBYwWR" class="wolai-block wolai-simple-table"><table><tbody><tr><td style="width: 79px"><span class="inline-wrap">Time</span></td><td style="width: 152px"><span class="inline-wrap">Speaker</span></td><td style="width: 630px"><span class="inline-wrap">Talk Title</span></td><td style="width: 111px"><span class="inline-wrap">Papers</span></td><td style="width: 90px"><span class="inline-wrap">Slides</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">3/12</span></td><td style="width: 152px"><span class="inline-wrap">Jia-Le Xu</span></td><td style="width: 630px"><span class="inline-wrap">Deep Forests</span></td><td style="width: 111px"><span class="inline-wrap"></span><br/></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/Deep Forests.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">4/7</span></td><td style="width: 152px"><span class="inline-wrap">Tian-Shuang Wu</span></td><td style="width: 630px"><span class="inline-wrap">Dataset Distillation</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/Dataset Distillation with Neural Characteristic Function A Minmax Perspective.pdf"><span>1</span></a></span><span class="inline-wrap">][</span><span class="inline-wrap"><a href="papers/Teacher as a lenient expert teacher-agnostic data-free knowledge distillation.pdf"><span>2</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/DataSetDistillation.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">4/21</span></td><td style="width: 152px"><span class="inline-wrap">Yu-Nian Wang</span></td><td style="width: 630px"><span class="inline-wrap">Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model (ICML 2024)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/eoh.pdf"><span>1</span></a></span><span class="inline-wrap">][</span><span class="inline-wrap"><a href="papers/funsearch.pdf"><span>2</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/LLM4AD.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">4/28</span></td><td style="width: 152px"><span class="inline-wrap">Lin-Kun Cui</span></td><td style="width: 630px"><span class="inline-wrap">A Game-Based Computation Offloading With Imperfect Information in Multi-Edge Environments (IEEE TSC 2025)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/A Game-Based Computation Offloading With Imperfect Information in Multi-Edge Environments.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/A Game-Based Computation Offloading With Imperfect Information in Multi-Edge Environments.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">6/2</span></td><td style="width: 152px"><span class="inline-wrap">Yu-Nian Wang</span></td><td style="width: 630px"><span class="inline-wrap">[Code] Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model (ICML 2024)</span></td><td style="width: 111px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="papers/eoh.pdf"><span>1</span></a></span><span class="inline-wrap">]</span></td><td style="width: 90px"><span class="inline-wrap">[</span><span class="inline-wrap"><a href="slides/LLM4AD code.pptx"><span>1</span></a></span><span class="inline-wrap">]</span></td></tr><tr><td style="width: 79px"><span class="inline-wrap">6/9</span></td><td style="width: 152px"><span class="inline-wrap">Yu Huang</span></td><td style="width: 630px"><span class="inline-wrap">Offline Model-Based Optimization</span></td><td style="width: 111px"><span class="inline-wrap"></span><br/></td><td style="width: 90px"><span class="inline-wrap"></span><br/></td></tr><tr><td style="width: 79px"><span class="inline-wrap"></span><br/></td><td style="width: 152px"><span class="inline-wrap"></span><br/></td><td style="width: 630px"><span class="inline-wrap"></span><br/></td><td style="width: 111px"><span class="inline-wrap"></span><br/></td><td style="width: 90px"><span class="inline-wrap"></span><br/></td></tr><tr><td style="width: 79px"><span class="inline-wrap"></span><br/></td><td style="width: 152px"><span class="inline-wrap"></span><br/></td><td style="width: 630px"><span class="inline-wrap"></span><br/></td><td style="width: 111px"><span class="inline-wrap"></span><br/></td><td style="width: 90px"><span class="inline-wrap"></span><br/></td></tr><tr><td style="width: 79px"><span class="inline-wrap"></span><br/></td><td style="width: 152px"><span class="inline-wrap"></span><br/></td><td style="width: 630px"><span class="inline-wrap"></span><br/></td><td style="width: 111px"><span class="inline-wrap"></span><br/></td><td style="width: 90px"><span class="inline-wrap"></span><br/></td></tr></tbody></table></div><h2 id="3uFT83aQGjgF5oKxun9ag7" class="wolai-block"><span class="inline-wrap">Organizers</span></h2><hr id="udwgKyKGcii5g2ufybyhnb" class="wolai-block"/><div id="2b2F4JjJJzJhzmvKeGnhzK" class="wolai-block wolai-text"><div><span class="inline-wrap"><a href="https://lyushenhuan.github.io/"><span>吕沈欢</span></a></span><span class="inline-wrap"> （河海大学）</span></div></div><h2 id="rZL8gMGqdefsvYLRPjYeQ7" class="wolai-block"><span class="inline-wrap">Contributors</span></h2><hr id="rktYvc4gVGA5dk1SZN5L7n" class="wolai-block"/><div id="mDDfYJvaToBXypNb7KV85e" class="wolai-block wolai-text"><div><span class="inline-wrap"><a href="https://tianshuangwu.github.io/"><span>吴填双</span></a></span><span class="inline-wrap">（河海大学）   </span><span class="inline-wrap"><a href="https://cnkeysky.github.io/"><span>陈宁</span></a></span><span class="inline-wrap">（河海大学）   许佳乐（河海大学）</span></div></div><div id="fjwGdTfuGncwz735TudNSy" class="wolai-block wolai-text"><div></div></div></article><footer></footer></body></html>